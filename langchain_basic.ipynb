{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (1.0.1)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain_openai)\n",
      "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from langchain_openai) (1.16.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (6.0.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
      "  Downloading langsmith-0.1.47-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.6.4)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (3.6)\n",
      "Requirement already satisfied: certifi in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain_openai) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (1.26.15)\n",
      "Requirement already satisfied: colorama in d:\\ml_ai_projects\\environ\\.conda\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
      "Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.5 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 163.8/287.5 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.5/287.5 kB 4.5 MB/s eta 0:00:00\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.47-py3-none-any.whl (113 kB)\n",
      "   ---------------------------------------- 0.0/113.0 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 92.2/113.0 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 113.0/113.0 kB 1.7 MB/s eta 0:00:00\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Installing collected packages: tenacity, packaging, jsonpointer, jsonpatch, langsmith, langchain-core, langchain_openai\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.42 langchain_openai-0.1.3 langsmith-0.1.47 packaging-23.2 tenacity-8.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")\n",
    "openai_api_key = os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=openai_api_key, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the cat sit on the computer?\\n\\nBecause it wanted to keep an eye on the mouse!', response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 14, 'total_tokens': 34}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-31274f44-442f-4fbe-ad81-88a1711b4296-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm.invoke(\"tell me a joke about a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are very helpful personal assistant\"),\n",
    "        (\"user\", \"I would like to know more about and understand {user_input}. Can you explain me more about it.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = chain.invoke({\"user_input\": \"Programming\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the cat sitting on the computer?\n",
      "\n",
      "Because it wanted to keep an eye on the mouse!\n"
     ]
    }
   ],
   "source": [
    "print(ai_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
